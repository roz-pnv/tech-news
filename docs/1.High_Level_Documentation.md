# TechNews Project Documentation

--- 
# 1. High-Level Documentation

## Project Overview

TechNews is a news aggregation platform designed to collect, store, and provide access to the latest technology-related news. It enables users to query and filter news articles through a REST API. The project also includes automated scraping of external news sources and scheduled updates to ensure that the data remains fresh.

## Goal of the Project

The primary goal of this system is to:

- Aggregate news from external sources (e.g., Zoomit).
- Provide a REST API to retrieve and filter news articles.
- Support complex filtering based on tags, keywords, and exclusion of specific terms.
- Keep the news database up-to-date using scheduled background tasks.
- Enable deployment in containerized environments for scalability and ease of maintenance.

## Overall Architecture

This project follows a **Monolithic architecture** implemented using Django and Django REST Framework. It is composed of two main Django apps alongside several supporting folders that help organize configuration, media, and documentation.

### Django Apps

- **news**  
  Handles storing, retrieving, and filtering news articles. This app includes the main API endpoints, data models (News, Tag, Image), and logic for article CRUD operations.

- **scraper_control**  
  Manages scraping operations using Scrapy and Selenium. It defines scheduled tasks with Celery and handles scraper-related data flow.


### Project-Level Directories

- **core**  
  Contains Django’s root configuration including `settings.py`, `urls.py`, and startup logic.

- **media**  
  Stores uploaded files such as news images.

- **static**  
  Holds static assets for the admin panel or any frontend integrations.

- **utils**  
  Includes shared helper functions or service modules reused across apps.

- **docs**  
  Contains internal documentation files, including Markdown (.md) files for architecture, models, and API descriptions.

- **data**  
  Temporary folder for storing raw scraped outputs or test inputs during development.

- **news_scraper**  
  Contains Scrapy spiders and scraping logic. This folder includes configurations, pipelines, and crawlers used to extract news from external websites. It works closely with Celery tasks for automation.


## Diagram Overview

### ERD (Entity-Relationship Diagram)
![ERD Diagram](./ERD-core.png)

#### Table: `news`
Stores the main content of each article.

| Field           | Type     | Description                                                                 |
|------------------|----------|-----------------------------------------------------------------------------|
| `id`             | int      | Unique identifier for each news article.                                    |
| `tags`           | int[]    | List of related tag IDs (for topic filtering).                              |
| `title`          | varchar  | Title of the article.                                                       |
| `slug`           | varchar  | URL-safe version of the title (used in API paths or web URLs).              |
| `body`           | text     | Full content of the news article.                                           |
| `summary`        | text     | Short summary shown in previews or list pages.                              |
| `source`         | varchar  | Source name (e.g. "Zoomit").                                                |
| `published_at`   | datetime | Date and time when the article was published online.                        |
| `created_at`     | datetime | Timestamp when the article was added to your database.                      |
| `updated_at`     | datetime | Last update time for this article data.                                     |

---

#### Table: `news_image`
Contains images linked to each news article.

| Field           | Type     | Description                                                                 |
|------------------|----------|-----------------------------------------------------------------------------|
| `id`             | int      | Unique image ID.                                                            |
| `news_id`        | int      | Foreign key linking to related news item.                                   |
| `image_file`     | image    | Uploaded image file (stored locally or on CDN).                             |
| `image_url`      | varchar  | External image link (if not stored directly).                               |
| `alt_text`       | varchar  | Alternative text shown if image can't load (useful for accessibility and SEO). |
| `is_main`        | boolean  | If true, this is the main image shown in the news list view (thumbnail or preview). Only one image per article should have this. |
| `position`       | int      | Number that controls the order of **other** images inside the article body. Lower numbers appear earlier. Optional field. |
| `created_at`     | datetime | Timestamp when the image was added.                                         |
| `updated_at`     | datetime | Timestamp for last image update.                                            |

---

#### Table: `tag`
Tags help categorize articles by topics.

| Field           | Type     | Description                                                                 |
|------------------|----------|-----------------------------------------------------------------------------|
| `id`             | int      | Unique ID for each tag.                                                     |
| `name`           | varchar  | Tag name shown to users (e.g. "AI", "Smartphones").                         |
| `slug`           | varchar  | URL-safe version of the tag name.                                           |
| `created_at`     | datetime | Timestamp when the tag was created.                                         |
| `updated_at`     | datetime | Timestamp when the tag was last updated.                                    |

---

#### Table: `ScrapedArticle`
Tracks raw scraped articles before converting to full news records.

| Field           | Type     | Description                                                                 |
|------------------|----------|-----------------------------------------------------------------------------|
| `id`             | int      | Unique ID for the scraped page.                                             |
| `url`            | varchar  | Link to the original page from which content was scraped.                   |
| `mapped_to`      | int/null | If available, links to corresponding `news.id`; otherwise stays null.       |

## Architecture Diagram

```
User
  ↓
Django REST API (DRF)
  ↓               ↓
Database       Celery Workers
                   ↓
               Scraper (Scrapy)
                   ↓
                 Redis
```

This diagram illustrates the backend architecture of the TechNews API system:

- **User**  
  Sends requests to view, filter, or manage news content through defined API endpoints.

- **Django REST API (DRF)**  
  Acts as the primary communication interface. It handles authentication, validation, and JSON responses. It can also delegate long-running tasks to background workers.

- **Database**  
  Stores all persistent data including articles, tags, images, and user information. Interacted with via Django ORM for reliable and consistent queries.

- **Celery Workers**  
  Execute asynchronous operations like launching the scraper or batch processing. Periodic tasks are scheduled via **celery-beat**, ensuring regular updates without manual intervention.

- **Scraper (Scrapy)**  
  Collects news articles from external sources. Powered by Scrapy and Selenium for dynamic content, it feeds structured data back into the database pipeline.

- **Redis**  
  Serves as both the task broker and result backend for Celery. It enables fast, reliable communication between Django and the background workers.



## Dependencies

Main dependencies used in the project:

- **Django**: Core web framework for building the application.
- **Django REST Framework (DRF)**: For building the REST API.
- **Celery**: For background tasks and periodic scraping.
- **Redis**: As the message broker for Celery.
- **Scrapy**: For web scraping and data collection.
- **django-celery-beat & django-celery-results**: For task scheduling and result tracking.
- **Docker & Docker Compose**: For containerization and deployment.
- **djangorestframework-simplejwt & djoser**: For authentication and user management.

External services:

- **Zoomit**: The primary source for scraping technology news.

This architecture ensures efficient data collection, flexible filtering options, and an easily maintainable codebase.
